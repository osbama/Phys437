{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgd2NvG8dvMP",
        "outputId": "6c01423b-ac37-414f-cc00-29acff276985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.11/dist-packages (0.41.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.7.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.41 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.41.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning>=0.41->pennylane) (0.3.29.0.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Requirement already satisfied: hvplot in /usr/local/lib/python3.11/dist-packages (0.11.2)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.11/dist-packages (from hvplot) (3.6.3)\n",
            "Requirement already satisfied: colorcet>=2 in /usr/local/lib/python3.11/dist-packages (from hvplot) (3.1.0)\n",
            "Requirement already satisfied: holoviews>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from hvplot) (1.20.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from hvplot) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hvplot) (24.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.11/dist-packages (from hvplot) (2.2.2)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.11/dist-packages (from hvplot) (1.6.2)\n",
            "Requirement already satisfied: param<3.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from hvplot) (2.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (2025.1.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.19.0->hvplot) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->hvplot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->hvplot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->hvplot) (2025.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (4.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=3.1->hvplot) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3->hvplot) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.0->hvplot) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.0->hvplot) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.0->hvplot) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->hvplot) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->hvplot) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->hvplot) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->hvplot) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane\n",
        "!pip install hvplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD_PWv5gdvMR"
      },
      "source": [
        "# Generative quantum eigensolver (GQE) training using PennyLane data\n",
        "\n",
        "\n",
        "We will be demonstrating and evaluating a novel algorithm proposed by\n",
        "Nakaji et al. in their paper [The generative quantum eigensolver (GQE)\n",
        "and its application for ground state\n",
        "search](https://arxiv.org/abs/2401.09253) that employs a classical\n",
        "generative model of quantum circuits for the purpose of ground-state\n",
        "energy estimation of any molecular Hamiltonian. It has been proposed as\n",
        "a scalable alternative to the variational quantum eigensolver\n",
        "(VQE) approach, where the\n",
        "quantum state is represented as a quantum circuit with tunable\n",
        "parameters which are then optimized during training in order to arrive\n",
        "at a state minimizing the corresponding energy $E.$ Instead, in GQE, the\n",
        "structure of the quantum circuit is given by a trained generative model.\n",
        "\n",
        "We will primarily focus on offline training on a fixed training dataset\n",
        "\\-- thanks to the molecular data available in [PennyLane\n",
        "Datasets](https://pennylane.ai/datasets/). By the end of the demo, we\n",
        "will show that the model gradually provides a better estimate for the\n",
        "energies and, in turn, can sample energies close to the ground state\n",
        "energy calculated by PennyLane.\n",
        "\n",
        "This demo is organized as follows. Firstly, we compare the GQE and VQE\n",
        "algorithms, and afterwards, we dive deeper in describing GPT-QE, i.e.,\n",
        "the GQE algorithm which uses a GPT model, and its training. Next, we\n",
        "generate the training dataset for our GPT model using PennyLane, and\n",
        "give details on our model architecture and training implementation.\n",
        "After that, we evaluate the model throughout its training and discuss\n",
        "its performance in estimating the ground state. And lastly, we discuss\n",
        "the results, potential ways optimizing the code, and its extension into\n",
        "the \\\"online training\\\" phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O31Wb_AsdvMT"
      },
      "source": [
        "## GQE vs. VQE\n",
        "\n",
        "\n",
        "Despite the relative success of VQE, there are some issues regarding its\n",
        "*trainability* for large problem instances. This shortcoming makes it\n",
        "less competitive against the performance of classical machine learning\n",
        "(ML) algorithms for large problems. To bypass this, the GQE algorithm\n",
        "was proposed. Specifically, GQE uses a classical generative model where\n",
        "quantum circuits are sampled as a sequence of unitaries from a given\n",
        "operator pool. This generative model is then trained so that it learns\n",
        "to predict quantum circuits that evolves an initial state to the states\n",
        "better approximating the ground state.\n",
        "\n",
        "The main difference between the two approaches is where the tunable\n",
        "parameters are embedded. That is, it is the classical GQE model that is\n",
        "being optimized as opposed to the variable quantum circuit of VQE.\n",
        "Potentially then, the\n",
        "`barren plateau` landscape of VQE and the quantum gradient evaluation of\n",
        "large circuits will be sidestepped by GQE, thus becoming more amenable\n",
        "for larger problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyyt1AWdvMT"
      },
      "source": [
        "![Figure 1: Diagrams of GQE and VQE from Fig. 1\n",
        "in](https://github.com/osbama/Phys437/blob/main/Hands-On/Hands_on_7_images/paper_gqe_vqe.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_em0j3uEdvMU"
      },
      "source": [
        "## GPT-QE background\n",
        "\n",
        "\n",
        "In particular, the model architecture used by Nakaji et al. for GQE was\n",
        "a generative pre-trained transformer (GPT),. This choice is then\n",
        "reflected in the name GPT-QE. As language models, GPTs are successful in\n",
        "generating sequences of words that closely resemble human natural\n",
        "language. This performance is harnessed for quantum chemistry by\n",
        "constructing quantum states $\\rho$ as a sequence of unitary operators\n",
        "which are, in turn, represented by quantum circuits. That is, we let\n",
        "$\\rho = U\\rho_0 U^{\\dagger}$ for some fixed initial state $\\rho_0$ and\n",
        "the aforementioned sequence is $U = U_{j_N}U_{j_{N-1}}\\cdots U_{j_1}.$\n",
        "The GPT model samples a sequence of integers $j_1, j_2, ..., j_N$\n",
        "indexing a pool of operators $U_j$ generated using molecular data from\n",
        "[PennyLane Molecules](https://pennylane.ai/datasets/qchem). We interpret\n",
        "these integers as tokens and the pool as the vocabulary in the parlance\n",
        "for language models. The goal of training is then to minimize the\n",
        "corresponding energy $E = \\mbox{Tr}(\\hat{H}\\rho),$ where $\\hat{H}$ is\n",
        "the Hamiltonian of the molecule in question.\n",
        "\n",
        "Each token $j_i$ is sampled from the distribution\n",
        "$\\exp(-\\beta w_{j_i}),$ where $w_{j_i}$ is the unnormalized log\n",
        "probability (or logit) returned by the GPT model for the token $j_i$ and\n",
        "$\\beta$ is an inverse temperature representing a trade-off parameter\n",
        "between exploration and exploitation. We then observe that the\n",
        "probability of sampling a state through the method described above is\n",
        "proportional to $\\exp(-\\beta w_{\\mbox{sum}}),$ where\n",
        "$w_{\\mbox{sum}} = \\sum_{i=1}^N w_{j_i}$ and the probability for the\n",
        "corresponding energy is $\\exp(-\\beta E).$ We thus have a constraint for\n",
        "the total logit to be equal to the energy of the corresponding state:\n",
        "$w_{\\mbox{sum}} = E,$ which can be imposed by training GPT-QE to\n",
        "minimize the loss function $C = (w_{\\mbox{sum}} - E)^2.$ With this\n",
        "constraint satisfied, GPT-QE would then be sampling states of smaller\n",
        "energies with increasing likelihood.\n",
        "\n",
        "More concretely, we summarize the *pre-*training loop in Figure 2. This\n",
        "is called pre-training because it involves learning from a fixed dataset\n",
        "first before transitioning to the \\\"real\\\" training which utilizes the\n",
        "data generated by the model itself. In this demo, we will call the\n",
        "pre-training as offline training since the GPT model does not receive\n",
        "feedback from the sequences it samples, and online training if\n",
        "otherwise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9GepePIdvMU"
      },
      "source": [
        "![Figure 2: Overview for offline training of\n",
        "GPT-QE](https://github.com/osbama/Phys437/blob/main/Hands-On/Hands_on_7_images/gqe_training_diagram.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0NupuPbdvMV"
      },
      "source": [
        "## Dataset construction via PennyLane\n",
        "\n",
        "\n",
        "Firstly, let us construct the static dataset we will use for offline\n",
        "training. We choose to generate our own dataset in order to illustrate\n",
        "the sequences and energies more concretely. Our dataset will be made\n",
        "from random sequences of tokens, which we recall corresponds to indices\n",
        "of a vocabulary of unitary operators. We then define an energy function\n",
        "in PennyLane to calculate the energy of a state corresponding to a token\n",
        "sequence. Applying the aforementioned function, we would then have a\n",
        "dataset of token sequences and energies for the GPT model offline\n",
        "training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOkFv53UdvMV"
      },
      "source": [
        "## Loading molecular information\n",
        "\n",
        "For simplicity, let us consider the [hydrogen\n",
        "molecule](https://pennylane.ai/datasets/qchem/h2-molecule) and load the\n",
        "corresponding dataset from PennyLane. Recall that we would need a\n",
        "vocabulary of operators $U_j$, an initial state $\\rho_0,$ and the\n",
        "Hamiltonian $\\hat{H}$ for a hydrogen molecule. We also get the ground\n",
        "state energy for later comparison with the results.\n",
        "\n",
        "Specifically, the unitary operators $U_j$ are time evolution operators\n",
        "as prescribed in. The non-identity operators are generated in PennyLane\n",
        "using `pennylane.SingleExcitation` and\n",
        "`pennylane.DoubleExcitation` which\n",
        "then depend on the number of electrons and orbitals of the molecule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L3dFifY9dvMV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "\n",
        "def generate_molecule_data(molecules=\"H2\"):\n",
        "    datasets = qml.data.load(\"qchem\", molname=molecules)\n",
        "\n",
        "    # Get the time set T\n",
        "    op_times = np.sort(np.array([-2**k for k in range(1, 5)] + [2**k for k in range(1, 5)]) / 160)\n",
        "\n",
        "    # Build operator set P for each molecule\n",
        "    molecule_data = dict()\n",
        "    for dataset in datasets:\n",
        "        molecule = dataset.molecule\n",
        "        num_electrons, num_qubits = molecule.n_electrons, 2 * molecule.n_orbitals\n",
        "        singles, doubles = qml.qchem.excitations(num_electrons, num_qubits)\n",
        "        double_excs = [qml.DoubleExcitation(time, wires=double) for double in doubles for time in op_times]\n",
        "        single_excs = [qml.SingleExcitation(time, wires=single) for single in singles for time in op_times]\n",
        "        identity_ops = [qml.exp(qml.I(range(num_qubits)), 1j*time) for time in op_times] # For Identity\n",
        "        operator_pool = double_excs + single_excs + identity_ops\n",
        "        molecule_data[dataset.molname] = {\n",
        "            \"op_pool\": np.array(operator_pool),\n",
        "            \"num_qubits\": num_qubits,\n",
        "            \"hf_state\": dataset.hf_state,\n",
        "            \"hamiltonian\": dataset.hamiltonian,\n",
        "            \"expected_ground_state_E\": dataset.fci_energy\n",
        "        }\n",
        "    return molecule_data\n",
        "\n",
        "molecule_data = generate_molecule_data(\"H2\")\n",
        "h2_data = molecule_data[\"H2\"]\n",
        "op_pool = h2_data[\"op_pool\"]\n",
        "num_qubits = h2_data[\"num_qubits\"]\n",
        "init_state = h2_data[\"hf_state\"]\n",
        "hamiltonian = h2_data[\"hamiltonian\"]\n",
        "grd_E = h2_data[\"expected_ground_state_E\"]\n",
        "op_pool_size = len(op_pool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS2lFDYwdvMW"
      },
      "source": [
        "## Defining the energy function\n",
        "\n",
        "\n",
        "In PennyLane, we define the energy function\n",
        "$E = \\mbox{Tr}(\\hat{H}U_{j_N}\\cdots U_{j_1}\\rho_0 U_{j_1}^{\\dagger}\\cdots U_{j_N}^{\\dagger})$\n",
        "corresponding to Eq. 1 of. Here, `energy_circuit` takes in the operator\n",
        "sequence $U_{j_1}, U_{j_2}, ..., U_{j_N}$ and returns the energy of the\n",
        "corresponding quantum state.\n",
        "\n",
        "As a slight extension, we can also calculate the energies for each\n",
        "subsequence of operators to help with the training of the model. That\n",
        "is, for a sequence of three operators $U_{j_1}, U_{j_2}, U_{j_3}$ we\n",
        "compute the energies for $U_{j_1}$ and $U_{j_1}, U_{j_2}$ instead of\n",
        "just the full sequence of three operators, which was described in. This\n",
        "can be done simply in PennyLane, using\n",
        "`pennylane.Snapshot` as shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0M0QIQ8cdvMW"
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def energy_circuit(gqe_ops):\n",
        "    # Computes Eq. 1 from Nakaji et al. based on the selected unitary operators\n",
        "    qml.BasisState(init_state, wires=range(num_qubits)) # Initial state <-- Hartree Fock state\n",
        "    for op in gqe_ops:\n",
        "        qml.Snapshot(measurement=qml.expval(hamiltonian))\n",
        "        qml.apply(op) # Applies each of the unitary operators\n",
        "    return qml.expval(hamiltonian)\n",
        "\n",
        "energy_circuit = qml.snapshots(energy_circuit)\n",
        "\n",
        "def get_subsequence_energies(op_seq):\n",
        "    # Collates the energies of each subsequence for a batch of sequences\n",
        "    energies = []\n",
        "    for ops in op_seq:\n",
        "        es = energy_circuit(ops)\n",
        "        energies.append(\n",
        "            [es[k].item() for k in list(range(1, len(ops))) + [\"execution_results\"]]\n",
        "        )\n",
        "    return np.array(energies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adIlQIEXdvMW"
      },
      "source": [
        "## Token sequence generation with corresponding energies\n",
        "\n",
        "\n",
        "With these ingredients, we can now construct a dataset containing\n",
        "sequences of tokens and their energies. Since we cannot feed the\n",
        "operators directly to the GPT model, we would need to tokenize them. The\n",
        "indices of `op_pool` seems to be a good candidate, but we instead choose\n",
        "the tokens to be the `op_pool` indices shifted by 1. This is so that we\n",
        "can define a special token `0` that tells the GPT model where the\n",
        "sequence starts.\n",
        "\n",
        "We generate a `train_size` number of random operator sequences of length\n",
        "`seq_len` for our purposes and calculate their energies (and their\n",
        "subsequences).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3l8sSqUYdvMX"
      },
      "outputs": [],
      "source": [
        "# Generate sequence of indices of operators in vocab\n",
        "train_size = 1024\n",
        "seq_len = 4\n",
        "train_op_pool_inds = np.random.randint(op_pool_size, size=(train_size, seq_len))\n",
        "\n",
        "# Corresponding sequence of operators\n",
        "train_op_seq = op_pool[train_op_pool_inds]\n",
        "\n",
        "# Corresponding tokens with special starting tokens\n",
        "train_token_seq = np.concatenate([\n",
        "    np.zeros(shape=(train_size, 1), dtype=int), # starting token is 0\n",
        "    train_op_pool_inds + 1 # shift operator inds by one\n",
        "], axis=1)\n",
        "\n",
        "# Calculate the energies for each subsequence in the training set\n",
        "train_sub_seq_en = get_subsequence_energies(train_op_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKTpZY-ZdvMX"
      },
      "source": [
        "## GPT-QE offline training\n",
        "\n",
        "\n",
        "Having setup our training dataset, we can start implementing our offline\n",
        "training loop as illustrated in Figure 2. We outline our implementation\n",
        "below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Q3snOTdvMX"
      },
      "source": [
        "## GPT model implementation details\n",
        "\n",
        "\n",
        "The GPT model we will use in this demo is mostly implemented in the\n",
        "[nanoGPT repo](https://github.com/karpathy/nanoGPT) (a reimplementation\n",
        "of the [OpenAI GPT-2](https://github.com/openai/gpt-2)) as the\n",
        "[class](https://github.com/karpathy/nanoGPT/blob/9755682b981a45507f6eb9b11eadef8cb83cebd5/model.py#L118)\n",
        "`GPT` with the model hyperparameters stored in the\n",
        "[dataclass](https://github.com/karpathy/nanoGPT/blob/9755682b981a45507f6eb9b11eadef8cb83cebd5/model.py#L109)\n",
        "`GPTConfig`. Namely, we will use 12 attention layers, 12 attention\n",
        "heads, and 768 embedding dimensions, which are equal to those described\n",
        "in. We can import from the nanoGPT repo directly by running the `curl`\n",
        "command (commented out below) in a Jupyter Notebook. Since nanoGPT is\n",
        "trained as a language model, its loss function and sampling method are\n",
        "defined differently. We then define the subclass `GPTQE` below to\n",
        "override some nanoGPT methods in order to make it more suitable for our\n",
        "case.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRDVGXTKdvMX",
        "outputId": "ebf18db8-f72d-4be8-81a6-0c4b03d3c200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 16345  100 16345    0     0  67439      0 --:--:-- --:--:-- --:--:-- 67263\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://raw.githubusercontent.com/karpathy/nanoGPT/master/model.py\n",
        "from model import GPT, GPTConfig\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class GPTQE(GPT):\n",
        "    def forward(self, idx):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    def calculate_loss(self, tokens, energies):\n",
        "        current_tokens, next_tokens = tokens[:, :-1], tokens[:, 1:]\n",
        "        # calculate the logits for the next possible tokens in the sequence\n",
        "        logits = self(current_tokens)\n",
        "        # get the logit for the actual next token in the sequence\n",
        "        next_token_mask = torch.nn.functional.one_hot(\n",
        "            next_tokens, num_classes=self.config.vocab_size\n",
        "        )\n",
        "        next_token_logits = (logits * next_token_mask).sum(axis=2)\n",
        "        # calculate the cumulative logits for each subsequence\n",
        "        cumsum_logits = torch.cumsum(next_token_logits, dim=1)\n",
        "        # match cumulative logits to subsequence energies\n",
        "        loss = torch.mean(torch.square(cumsum_logits - energies))\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, n_sequences, max_new_tokens, temperature=1.0, device=\"cpu\"):\n",
        "        idx = torch.zeros(size=(n_sequences, 1), dtype=int, device=device)\n",
        "        total_logits = torch.zeros(size=(n_sequences, 1), device=device)\n",
        "        for _ in range(max_new_tokens):\n",
        "            # if the sequence context is growing too long we must crop it at block_size\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            # forward the model to get the logits for the index in the sequence\n",
        "            logits = self(idx_cond)\n",
        "            # pluck the logits at the final step\n",
        "            logits = logits[:, -1, :]\n",
        "            # set the logit of the first token so that its probability will be zero\n",
        "            logits[:, 0] = float(\"inf\")\n",
        "            # apply softmax to convert logits to (normalized) probabilities and scale by desired temperature\n",
        "            probs = F.softmax(-logits / temperature, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # # Accumulate logits\n",
        "            total_logits += torch.gather(logits, index=idx_next, dim=1)\n",
        "            # append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx, total_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4rlL4krdvMX"
      },
      "source": [
        "However, it is important to note that the loss function\n",
        "`calculate_loss`, that we defined is different from the one described in\n",
        "which is $(\\exp(-w_{\\mbox{sum}}) - \\exp(-E))^2.$ As described\n",
        "beforehand, we instead directly compute the mean squared error between\n",
        "$w_{\\mbox{sum}}$ and $E.$ Since the exponential function is one-to-one,\n",
        "both loss functions would then impose the same minimum. Using the error\n",
        "between exponentials may even introduce numerical instabilities in the\n",
        "training since the loss would be taking differences of potentially large\n",
        "numbers. In addition to this change from, we also use the error between\n",
        "the cumulative sum of logits and the corresponding energy for each\n",
        "subsequence instead of just the error between total logits and the\n",
        "energy of an entire sequence. This addition will give more training data\n",
        "to the model and should help with logit matching the intermediate\n",
        "tokens.\n",
        "\n",
        "Since it was not explicitly shown in, another possible deviation we made\n",
        "is with the logit calculation during offline training. It seems that the\n",
        "logits were accumulated by looping through the sequential generation of\n",
        "tokens. In order to fill in the blanks, we implement the logit\n",
        "calculation in a manner that we think is efficient. Namely, we directly\n",
        "pass the fixed training sequences to the model and retrieve the relevant\n",
        "logits from it. This can be done because we are using a causal mask for\n",
        "the attention blocks so that the logits of the earlier tokens in the\n",
        "sequence are not affected by tokens in the later part of the sequence.\n",
        "Thus, having the same effect of the sequential token generation.\n",
        "\n",
        "We initialize our GPT model below and we see that it has around 85\n",
        "million parameters. When saved, the model is `324.25 MB` in size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m7R2-0JdvMX",
        "outputId": "28b04289-12d3-4a89-baa4-bcfad451c4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 84.98M\n",
            "num decayed parameter tensors: 50, with 84,963,072 parameters\n",
            "num non-decayed parameter tensors: 25, with 19,200 parameters\n",
            "using fused AdamW: True\n"
          ]
        }
      ],
      "source": [
        "# Uncomment for cuda\n",
        "tokens = torch.from_numpy(train_token_seq).to(\"cuda\")\n",
        "energies = torch.from_numpy(train_sub_seq_en).to(\"cuda\")\n",
        "gpt = GPTQE(GPTConfig(\n",
        "    vocab_size=op_pool_size + 1,\n",
        "    block_size=seq_len,\n",
        "    dropout=0.2,\n",
        "    bias=False\n",
        ")).to(\"cuda\")\n",
        "opt = gpt.configure_optimizers(\n",
        "    weight_decay=0.01, learning_rate=5e-5, betas=(0.9, 0.999), device_type=\"cuda\"\n",
        ")\n",
        "# Uncomment for CPU only\n",
        "#tokens = torch.from_numpy(train_token_seq).to(\"cpu\")\n",
        "#energies = torch.from_numpy(train_sub_seq_en).to(\"cpu\")\n",
        "#gpt = GPTQE(GPTConfig(\n",
        "#    vocab_size=op_pool_size + 1,\n",
        "#    block_size=seq_len,\n",
        "#    dropout=0.2,\n",
        "#    bias=False\n",
        "#)).to(\"cpu\")\n",
        "#opt = gpt.configure_optimizers(\n",
        "#    weight_decay=0.01, learning_rate=5e-5, betas=(0.9, 0.999), device_type=\"cpu\"\n",
        "#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3qFYttpdvMY"
      },
      "source": [
        "## GPT offline training\n",
        "\n",
        "\n",
        "We now implement a training loop for our GPT model. This can be framed\n",
        "as a straightforward supervised learning problem. We sketch the steps\n",
        "for each training iteration/epoch below:\n",
        "\n",
        "1.  Shuffle the training set and split it into `n_batches` minibatches\n",
        "2.  For each minibatch, calculate the average loss, the gradients, and\n",
        "    take an optimizer step\n",
        "3.  For each n-th iteration (n is 500 here), evaluate the GPT model:\n",
        "    -   Generate a batch of sequences and the predicted energies (total\n",
        "        logits). Note that these are not necessarily same sequences as\n",
        "        in the training set.\n",
        "    -   Calculate the true energies using PennyLane\n",
        "    -   Calculate the mean absolute error as a metric to track the\n",
        "        learning progress and save the GPT model everytime the metric\n",
        "        gets better\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HMA678yTdvMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe5a203-479d-4b40-891d-31ef05c971d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500, Loss: 0.0014135475107007482, MAE: 0.11884131046133634, Ave E: -1.117815450708097\n",
            "Saved model!\n",
            "Iteration: 1000, Loss: 0.0004031187919955817, MAE: 0.06793401534272335, Ave E: -1.1335656613616836\n",
            "Saved model!\n",
            "Iteration: 1500, Loss: 0.00025260052855528457, MAE: 0.041898395720122134, Ave E: -1.1362413313955089\n",
            "Saved model!\n",
            "Iteration: 2000, Loss: 9.475917093031285e-05, MAE: 0.031593430093673616, Ave E: -1.1367157113038027\n",
            "Saved model!\n",
            "Iteration: 2500, Loss: 7.541233426676345e-05, MAE: 0.03709005682084388, Ave E: -1.1369822088041561\n",
            "Iteration: 3000, Loss: 2.6103237077201977e-05, MAE: 0.006161487130446517, Ave E: -1.136048014136033\n",
            "Saved model!\n",
            "Iteration: 3500, Loss: 1.6833034239072115e-05, MAE: 0.0015962348056710817, Ave E: -1.1362991580578592\n",
            "Saved model!\n",
            "Iteration: 4000, Loss: 1.876335190321789e-05, MAE: 0.019828561975432334, Ave E: -1.1337116654377453\n",
            "Iteration: 4500, Loss: 1.8406272668107033e-05, MAE: 0.003531638587569417, Ave E: -1.1359259183721684\n",
            "Iteration: 5000, Loss: 1.27941466003852e-05, MAE: 0.009423353043216115, Ave E: -1.1362777334779326\n",
            "Iteration: 5500, Loss: 9.801606089728412e-06, MAE: 0.008966535403247022, Ave E: -1.134682546780591\n",
            "Iteration: 6000, Loss: 9.90426014955892e-06, MAE: 0.015113225614308841, Ave E: -1.13371717151475\n",
            "Iteration: 6500, Loss: 0.00022999408981287097, MAE: 0.07106488395431282, Ave E: -1.1341244037081935\n",
            "Iteration: 7000, Loss: 1.4201658834519992e-05, MAE: 0.007928769876782225, Ave E: -1.1363604709603148\n",
            "Iteration: 7500, Loss: 8.4040642776771e-06, MAE: 0.0019265034686579586, Ave E: -1.1353019427509552\n",
            "Iteration: 8000, Loss: 1.6442870520962833e-05, MAE: 0.02348983641327458, Ave E: -1.1305429995471135\n",
            "Iteration: 8500, Loss: 9.417904533691639e-06, MAE: 0.0067487236555328735, Ave E: -1.1352568784658204\n",
            "Iteration: 9000, Loss: 5.0743886282040866e-06, MAE: 0.02238664937123306, Ave E: -1.1281319980610944\n",
            "Iteration: 9500, Loss: 4.7935061889573665e-06, MAE: 0.021071368638750424, Ave E: -1.1285289631445445\n",
            "Iteration: 10000, Loss: 4.328184100179107e-06, MAE: 0.005648034185088362, Ave E: -1.135758882320325\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "n_batches = 8\n",
        "train_inds = np.arange(train_size)\n",
        "\n",
        "losses = []\n",
        "pred_Es_t = []\n",
        "true_Es_t = []\n",
        "current_mae = 10000\n",
        "gpt.train()\n",
        "for i in range(10000):\n",
        "    # Shuffle batches of the training set\n",
        "    np.random.shuffle(train_inds)\n",
        "    token_batches = torch.tensor_split(tokens[train_inds], n_batches)\n",
        "    energy_batches = torch.tensor_split(energies[train_inds], n_batches)\n",
        "\n",
        "    # SGD on random minibatches\n",
        "    loss_record = 0\n",
        "    for token_batch, energy_batch in zip(token_batches, energy_batches):\n",
        "        opt.zero_grad()\n",
        "        loss = gpt.calculate_loss(token_batch, energy_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        loss_record += loss.item() / n_batches\n",
        "    losses.append(loss_record)\n",
        "\n",
        "    if (i+1) % 500 == 0:\n",
        "        # For GPT evaluation\n",
        "        gpt.eval()\n",
        "        gen_token_seq, pred_Es = gpt.generate(\n",
        "            n_sequences=100,\n",
        "            max_new_tokens=seq_len,\n",
        "            temperature=0.001, # Use a low temperature to emphasize the difference in logits\n",
        "            device=\"cuda\"\n",
        "        )\n",
        "        pred_Es = pred_Es.cpu().numpy()\n",
        "\n",
        "        gen_inds = (gen_token_seq[:, 1:] - 1).cpu().numpy()\n",
        "        gen_op_seq = op_pool[gen_inds]\n",
        "        true_Es = get_subsequence_energies(gen_op_seq)[:, -1].reshape(-1, 1)\n",
        "\n",
        "        mae = np.mean(np.abs(pred_Es - true_Es))\n",
        "        ave_E = np.mean(true_Es)\n",
        "\n",
        "        pred_Es_t.append(pred_Es)\n",
        "        true_Es_t.append(true_Es)\n",
        "\n",
        "        print(f\"Iteration: {i+1}, Loss: {losses[-1]}, MAE: {mae}, Ave E: {ave_E}\")\n",
        "\n",
        "        if mae < current_mae:\n",
        "            current_mae = mae\n",
        "            # Create the directory if it doesn't exist\n",
        "            os.makedirs(f\"./seq_len={seq_len}\", exist_ok=True)\n",
        "            torch.save(gpt, f\"./seq_len={seq_len}/gqe.pt\")\n",
        "            print(\"Saved model!\")\n",
        "\n",
        "        gpt.train()\n",
        "\n",
        "pred_Es_t = np.concatenate(pred_Es_t, axis=1)\n",
        "true_Es_t = np.concatenate(true_Es_t, axis=1)\n",
        "pd.DataFrame(losses).to_csv(f\"./seq_len={seq_len}/losses.csv\", index=False)\n",
        "pd.DataFrame(pred_Es_t).to_csv(f\"./seq_len={seq_len}/pred_Es_t.csv\", index=False)\n",
        "pd.DataFrame(true_Es_t).to_csv(f\"./seq_len={seq_len}/true_Es_t.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EMlYkoYdvMY"
      },
      "source": [
        "With a preliminary look at the training logs above, we see that the\n",
        "offline training took 2 h and 12 min for 10,000 training iterations. The\n",
        "code execution time was measured by including the `%%time` magic command\n",
        "before the code block. We also note that the mean absolute error between\n",
        "the predicted and true energies for the generated sequences quickly\n",
        "became smaller during the earlier parts of the training but fluctuates\n",
        "more later on. As mentioned earlier, a model version is saved each time\n",
        "we get better performance. The best model version is then saved at the\n",
        "7,000th iteration, where the mean absolute error is at its lowest. The\n",
        "other quantities we observe are the average true energies of the\n",
        "generated sequences. It is then promising to see that throughout\n",
        "training, this is close to the ground state energy\n",
        "`grd_E=-1.1372633205048763 Ha`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzn_eDGFdvMY"
      },
      "source": [
        "## GPT-QE results\n",
        "\n",
        "\n",
        "Having finished the offline training, let\\'s take a look at some of our\n",
        "results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMxt2YmsdvMY"
      },
      "source": [
        "## Training loss curve\n",
        "\n",
        "\n",
        "One of the first things we can look at is the training loss curve.\n",
        "Recall that for our case, the loss is the mean squared error between the\n",
        "cumulative sum of logits (predicted subsequence energies) and their\n",
        "corresponding true subsequence energies. So reducing this quantity\n",
        "allows the model to be better at giving correct energies and in turn,\n",
        "correctly sample sequences with lower energies. Since the raw loss\n",
        "values become very small, we instead plot the loss in log-scale below to\n",
        "magnify the loss trend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1SWLgAuydvMZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "6729395d-3e73-4408-a492-9d79703ed6b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  const force = true;\n",
              "  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
              "  const reloading = false;\n",
              "  const Bokeh = root.Bokeh;\n",
              "\n",
              "  // Set a timeout for this load but only if we are not already initializing\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks;\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "    if (js_modules == null) js_modules = [];\n",
              "    if (js_exports == null) js_exports = {};\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      // Don't load bokeh if it is still initializing\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
              "      // There is nothing to load\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "    window._bokeh_on_load = on_load\n",
              "\n",
              "    function on_error(e) {\n",
              "      const src_el = e.srcElement\n",
              "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
              "    }\n",
              "\n",
              "    const skip = [];\n",
              "    if (window.requirejs) {\n",
              "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
              "      root._bokeh_is_loading = css_urls.length + 0;\n",
              "    } else {\n",
              "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
              "    }\n",
              "\n",
              "    const existing_stylesheets = []\n",
              "    const links = document.getElementsByTagName('link')\n",
              "    for (let i = 0; i < links.length; i++) {\n",
              "      const link = links[i]\n",
              "      if (link.href != null) {\n",
              "        existing_stylesheets.push(link.href)\n",
              "      }\n",
              "    }\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
              "        on_load()\n",
              "        continue;\n",
              "      }\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }    var existing_scripts = []\n",
              "    const scripts = document.getElementsByTagName('script')\n",
              "    for (let i = 0; i < scripts.length; i++) {\n",
              "      var script = scripts[i]\n",
              "      if (script.src != null) {\n",
              "        existing_scripts.push(script.src)\n",
              "      }\n",
              "    }\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
              "        if (!window.requirejs) {\n",
              "          on_load();\n",
              "        }\n",
              "        continue;\n",
              "      }\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (let i = 0; i < js_modules.length; i++) {\n",
              "      const url = js_modules[i];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
              "        if (!window.requirejs) {\n",
              "          on_load();\n",
              "        }\n",
              "        continue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (const name in js_exports) {\n",
              "      const url = js_exports[name];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
              "        if (!window.requirejs) {\n",
              "          on_load();\n",
              "        }\n",
              "        continue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      element.textContent = `\n",
              "      import ${name} from \"${url}\"\n",
              "      window.${name} = ${name}\n",
              "      window._bokeh_on_load()\n",
              "      `\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    if (!js_urls.length && !js_modules.length) {\n",
              "      on_load()\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.2/dist/panel.min.js\"];\n",
              "  const js_modules = [];\n",
              "  const js_exports = {};\n",
              "  const css_urls = [];\n",
              "  const inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {} // ensure no trailing comma for IE\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (let i = 0; i < inline_js.length; i++) {\n",
              "        try {\n",
              "          inline_js[i].call(root, root.Bokeh);\n",
              "        } catch(e) {\n",
              "          if (!reloading) {\n",
              "            throw e;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      // Cache old bokeh versions\n",
              "      if (Bokeh != undefined && !reloading) {\n",
              "        var NewBokeh = root.Bokeh;\n",
              "        if (Bokeh.versions === undefined) {\n",
              "          Bokeh.versions = new Map();\n",
              "        }\n",
              "        if (NewBokeh.version !== Bokeh.version) {\n",
              "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
              "        }\n",
              "        root.Bokeh = Bokeh;\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    }\n",
              "    root._bokeh_is_initializing = false\n",
              "  }\n",
              "\n",
              "  function load_or_wait() {\n",
              "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
              "    // versions of Bokeh and its dependencies at the same time.\n",
              "    // In recent versions we use the root._bokeh_is_initializing flag\n",
              "    // to determine whether there is an ongoing attempt to initialize\n",
              "    // bokeh, however for backward compatibility we also try to ensure\n",
              "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
              "    // before older versions are fully initialized.\n",
              "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
              "      // If the timeout and bokeh was not successfully loaded we reset\n",
              "      // everything and try loading again\n",
              "      root._bokeh_timeout = Date.now() + 5000;\n",
              "      root._bokeh_is_initializing = false;\n",
              "      root._bokeh_onload_callbacks = undefined;\n",
              "      root._bokeh_is_loading = 0\n",
              "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
              "      load_or_wait();\n",
              "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
              "      setTimeout(load_or_wait, 100);\n",
              "    } else {\n",
              "      root._bokeh_is_initializing = true\n",
              "      root._bokeh_onload_callbacks = []\n",
              "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
              "      if (!reloading && !bokeh_loaded) {\n",
              "        if (root.Bokeh) {\n",
              "          root.Bokeh = undefined;\n",
              "        }\n",
              "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "      }\n",
              "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
              "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "        run_inline_js();\n",
              "      });\n",
              "    }\n",
              "  }\n",
              "  // Give older versions of the autoload script a head-start to ensure\n",
              "  // they initialize before we start loading newer version.\n",
              "  setTimeout(load_or_wait, 100)\n",
              "}(window));"
            ],
            "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.2/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/javascript": [
              "\n",
              "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
              "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
              "}\n",
              "\n",
              "\n",
              "    function JupyterCommManager() {\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
              "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        comm_manager.register_target(comm_id, function(comm) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        });\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        });\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
              "          var messages = comm.messages[Symbol.asyncIterator]();\n",
              "          function processIteratorResult(result) {\n",
              "            var message = result.value;\n",
              "            console.log(message)\n",
              "            var content = {data: message.data, comm_id};\n",
              "            var buffers = []\n",
              "            for (var buffer of message.buffers || []) {\n",
              "              buffers.push(new DataView(buffer))\n",
              "            }\n",
              "            var metadata = message.metadata || {};\n",
              "            var msg = {content, buffers, metadata}\n",
              "            msg_handler(msg);\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "          return messages.next().then(processIteratorResult);\n",
              "        })\n",
              "      }\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
              "      if (comm_id in window.PyViz.comms) {\n",
              "        return window.PyViz.comms[comm_id];\n",
              "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
              "        if (msg_handler) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        }\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
              "        comm.open();\n",
              "        if (msg_handler) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        }\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
              "        comm_promise.then((comm) => {\n",
              "          window.PyViz.comms[comm_id] = comm;\n",
              "          if (msg_handler) {\n",
              "            var messages = comm.messages[Symbol.asyncIterator]();\n",
              "            function processIteratorResult(result) {\n",
              "              var message = result.value;\n",
              "              var content = {data: message.data};\n",
              "              var metadata = message.metadata || {comm_id};\n",
              "              var msg = {content, metadata}\n",
              "              msg_handler(msg);\n",
              "              return messages.next().then(processIteratorResult);\n",
              "            }\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "        })\n",
              "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
              "          return comm_promise.then((comm) => {\n",
              "            comm.send(data, metadata, buffers, disposeOnDone);\n",
              "          });\n",
              "        };\n",
              "        var comm = {\n",
              "          send: sendClosure\n",
              "        };\n",
              "      }\n",
              "      window.PyViz.comms[comm_id] = comm;\n",
              "      return comm;\n",
              "    }\n",
              "    window.PyViz.comm_manager = new JupyterCommManager();\n",
              "    \n",
              "\n",
              "\n",
              "var JS_MIME_TYPE = 'application/javascript';\n",
              "var HTML_MIME_TYPE = 'text/html';\n",
              "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
              "var CLASS_NAME = 'output';\n",
              "\n",
              "/**\n",
              " * Render data to the DOM node\n",
              " */\n",
              "function render(props, node) {\n",
              "  var div = document.createElement(\"div\");\n",
              "  var script = document.createElement(\"script\");\n",
              "  node.appendChild(div);\n",
              "  node.appendChild(script);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when a new output is added\n",
              " */\n",
              "function handle_add_output(event, handle) {\n",
              "  var output_area = handle.output_area;\n",
              "  var output = handle.output;\n",
              "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "    return\n",
              "  }\n",
              "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "  if (id !== undefined) {\n",
              "    var nchildren = toinsert.length;\n",
              "    var html_node = toinsert[nchildren-1].children[0];\n",
              "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var scripts = [];\n",
              "    var nodelist = html_node.querySelectorAll(\"script\");\n",
              "    for (var i in nodelist) {\n",
              "      if (nodelist.hasOwnProperty(i)) {\n",
              "        scripts.push(nodelist[i])\n",
              "      }\n",
              "    }\n",
              "\n",
              "    scripts.forEach( function (oldScript) {\n",
              "      var newScript = document.createElement(\"script\");\n",
              "      var attrs = [];\n",
              "      var nodemap = oldScript.attributes;\n",
              "      for (var j in nodemap) {\n",
              "        if (nodemap.hasOwnProperty(j)) {\n",
              "          attrs.push(nodemap[j])\n",
              "        }\n",
              "      }\n",
              "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
              "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
              "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
              "    });\n",
              "    if (JS_MIME_TYPE in output.data) {\n",
              "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
              "    }\n",
              "    output_area._hv_plot_id = id;\n",
              "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
              "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
              "    } else {\n",
              "      window.PyViz.plot_index[id] = null;\n",
              "    }\n",
              "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "    var bk_div = document.createElement(\"div\");\n",
              "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var script_attrs = bk_div.children[0].attributes;\n",
              "    for (var i = 0; i < script_attrs.length; i++) {\n",
              "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "    }\n",
              "    // store reference to server id on output_area\n",
              "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when an output is cleared or removed\n",
              " */\n",
              "function handle_clear_output(event, handle) {\n",
              "  var id = handle.cell.output_area._hv_plot_id;\n",
              "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
              "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
              "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
              "  if (server_id !== null) {\n",
              "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
              "    return;\n",
              "  } else if (comm !== null) {\n",
              "    comm.send({event_type: 'delete', 'id': id});\n",
              "  }\n",
              "  delete PyViz.plot_index[id];\n",
              "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
              "    var doc = window.Bokeh.index[id].model.document\n",
              "    doc.clear();\n",
              "    const i = window.Bokeh.documents.indexOf(doc);\n",
              "    if (i > -1) {\n",
              "      window.Bokeh.documents.splice(i, 1);\n",
              "    }\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle kernel restart event\n",
              " */\n",
              "function handle_kernel_cleanup(event, handle) {\n",
              "  delete PyViz.comms[\"hv-extension-comm\"];\n",
              "  window.PyViz.plot_index = {}\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle update_display_data messages\n",
              " */\n",
              "function handle_update_output(event, handle) {\n",
              "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
              "  handle_add_output(event, handle)\n",
              "}\n",
              "\n",
              "function register_renderer(events, OutputArea) {\n",
              "  function append_mime(data, metadata, element) {\n",
              "    // create a DOM node to render to\n",
              "    var toinsert = this.create_output_subarea(\n",
              "    metadata,\n",
              "    CLASS_NAME,\n",
              "    EXEC_MIME_TYPE\n",
              "    );\n",
              "    this.keyboard_manager.register_events(toinsert);\n",
              "    // Render to node\n",
              "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "    render(props, toinsert[0]);\n",
              "    element.append(toinsert);\n",
              "    return toinsert\n",
              "  }\n",
              "\n",
              "  events.on('output_added.OutputArea', handle_add_output);\n",
              "  events.on('output_updated.OutputArea', handle_update_output);\n",
              "  events.on('clear_output.CodeCell', handle_clear_output);\n",
              "  events.on('delete.Cell', handle_clear_output);\n",
              "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
              "\n",
              "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "    safe: true,\n",
              "    index: 0\n",
              "  });\n",
              "}\n",
              "\n",
              "if (window.Jupyter !== undefined) {\n",
              "  try {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  } catch(err) {\n",
              "  }\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='f3adf376-b698-4ba4-9349-7a5003d63237'>\n",
              "  <div id=\"f46f2f6f-b023-4270-917b-4cf1be2a9ad5\" data-root-id=\"f3adf376-b698-4ba4-9349-7a5003d63237\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"2984558a-7210-4f07-bf3d-594489fbe23d\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"f3adf376-b698-4ba4-9349-7a5003d63237\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"dad791fa-26c9-4ce1-8cb2-79c40f5d6251\",\"attributes\":{\"plot_id\":\"f3adf376-b698-4ba4-9349-7a5003d63237\",\"comm_id\":\"e22d8f709f66438dbe15537347e4048f\",\"client_comm_id\":\"71bbe34f95d24ee7b1293427350c0fa9\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"2984558a-7210-4f07-bf3d-594489fbe23d\",\"roots\":{\"f3adf376-b698-4ba4-9349-7a5003d63237\":\"f46f2f6f-b023-4270-917b-4cf1be2a9ad5\"},\"root_ids\":[\"f3adf376-b698-4ba4-9349-7a5003d63237\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ],
            "application/vnd.holoviews_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "f3adf376-b698-4ba4-9349-7a5003d63237"
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  const force = false;\n",
              "  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
              "  const reloading = true;\n",
              "  const Bokeh = root.Bokeh;\n",
              "\n",
              "  // Set a timeout for this load but only if we are not already initializing\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks;\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "    if (js_modules == null) js_modules = [];\n",
              "    if (js_exports == null) js_exports = {};\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      // Don't load bokeh if it is still initializing\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
              "      // There is nothing to load\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "    window._bokeh_on_load = on_load\n",
              "\n",
              "    function on_error(e) {\n",
              "      const src_el = e.srcElement\n",
              "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
              "    }\n",
              "\n",
              "    const skip = [];\n",
              "    if (window.requirejs) {\n",
              "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
              "      root._bokeh_is_loading = css_urls.length + 0;\n",
              "    } else {\n",
              "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
              "    }\n",
              "\n",
              "    const existing_stylesheets = []\n",
              "    const links = document.getElementsByTagName('link')\n",
              "    for (let i = 0; i < links.length; i++) {\n",
              "      const link = links[i]\n",
              "      if (link.href != null) {\n",
              "        existing_stylesheets.push(link.href)\n",
              "      }\n",
              "    }\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
              "        on_load()\n",
              "        continue;\n",
              "      }\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }    var existing_scripts = []\n",
              "    const scripts = document.getElementsByTagName('script')\n",
              "    for (let i = 0; i < scripts.length; i++) {\n",
              "      var script = scripts[i]\n",
              "      if (script.src != null) {\n",
              "        existing_scripts.push(script.src)\n",
              "      }\n",
              "    }\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
              "        if (!window.requirejs) {\n",
              "          on_load();\n",
              "        }\n",
              "        continue;\n",
              "      }\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (let i = 0; i < js_modules.length; i++) {\n",
              "      const url = js_modules[i];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
              "        if (!window.requirejs) {\n",
              "          on_load();\n",
              "        }\n",
              "        continue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (const name in js_exports) {\n",
              "      const url = js_exports[name];\n",
              "      const escaped = encodeURI(url)\n",
              "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
              "        if (!window.requirejs) {\n",
              "          on_load();\n",
              "        }\n",
              "        continue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      element.textContent = `\n",
              "      import ${name} from \"${url}\"\n",
              "      window.${name} = ${name}\n",
              "      window._bokeh_on_load()\n",
              "      `\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    if (!js_urls.length && !js_modules.length) {\n",
              "      on_load()\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n",
              "  const js_modules = [];\n",
              "  const js_exports = {};\n",
              "  const css_urls = [];\n",
              "  const inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {} // ensure no trailing comma for IE\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (let i = 0; i < inline_js.length; i++) {\n",
              "        try {\n",
              "          inline_js[i].call(root, root.Bokeh);\n",
              "        } catch(e) {\n",
              "          if (!reloading) {\n",
              "            throw e;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      // Cache old bokeh versions\n",
              "      if (Bokeh != undefined && !reloading) {\n",
              "        var NewBokeh = root.Bokeh;\n",
              "        if (Bokeh.versions === undefined) {\n",
              "          Bokeh.versions = new Map();\n",
              "        }\n",
              "        if (NewBokeh.version !== Bokeh.version) {\n",
              "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
              "        }\n",
              "        root.Bokeh = Bokeh;\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    }\n",
              "    root._bokeh_is_initializing = false\n",
              "  }\n",
              "\n",
              "  function load_or_wait() {\n",
              "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
              "    // versions of Bokeh and its dependencies at the same time.\n",
              "    // In recent versions we use the root._bokeh_is_initializing flag\n",
              "    // to determine whether there is an ongoing attempt to initialize\n",
              "    // bokeh, however for backward compatibility we also try to ensure\n",
              "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
              "    // before older versions are fully initialized.\n",
              "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
              "      // If the timeout and bokeh was not successfully loaded we reset\n",
              "      // everything and try loading again\n",
              "      root._bokeh_timeout = Date.now() + 5000;\n",
              "      root._bokeh_is_initializing = false;\n",
              "      root._bokeh_onload_callbacks = undefined;\n",
              "      root._bokeh_is_loading = 0\n",
              "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
              "      load_or_wait();\n",
              "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
              "      setTimeout(load_or_wait, 100);\n",
              "    } else {\n",
              "      root._bokeh_is_initializing = true\n",
              "      root._bokeh_onload_callbacks = []\n",
              "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
              "      if (!reloading && !bokeh_loaded) {\n",
              "        if (root.Bokeh) {\n",
              "          root.Bokeh = undefined;\n",
              "        }\n",
              "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "      }\n",
              "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
              "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "        run_inline_js();\n",
              "      });\n",
              "    }\n",
              "  }\n",
              "  // Give older versions of the autoload script a head-start to ensure\n",
              "  // they initialize before we start loading newer version.\n",
              "  setTimeout(load_or_wait, 100)\n",
              "}(window));"
            ],
            "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/javascript": [
              "\n",
              "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
              "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
              "}\n",
              "\n",
              "\n",
              "    function JupyterCommManager() {\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
              "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        comm_manager.register_target(comm_id, function(comm) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        });\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        });\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
              "          var messages = comm.messages[Symbol.asyncIterator]();\n",
              "          function processIteratorResult(result) {\n",
              "            var message = result.value;\n",
              "            console.log(message)\n",
              "            var content = {data: message.data, comm_id};\n",
              "            var buffers = []\n",
              "            for (var buffer of message.buffers || []) {\n",
              "              buffers.push(new DataView(buffer))\n",
              "            }\n",
              "            var metadata = message.metadata || {};\n",
              "            var msg = {content, buffers, metadata}\n",
              "            msg_handler(msg);\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "          return messages.next().then(processIteratorResult);\n",
              "        })\n",
              "      }\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
              "      if (comm_id in window.PyViz.comms) {\n",
              "        return window.PyViz.comms[comm_id];\n",
              "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
              "        if (msg_handler) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        }\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
              "        comm.open();\n",
              "        if (msg_handler) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        }\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
              "        comm_promise.then((comm) => {\n",
              "          window.PyViz.comms[comm_id] = comm;\n",
              "          if (msg_handler) {\n",
              "            var messages = comm.messages[Symbol.asyncIterator]();\n",
              "            function processIteratorResult(result) {\n",
              "              var message = result.value;\n",
              "              var content = {data: message.data};\n",
              "              var metadata = message.metadata || {comm_id};\n",
              "              var msg = {content, metadata}\n",
              "              msg_handler(msg);\n",
              "              return messages.next().then(processIteratorResult);\n",
              "            }\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "        })\n",
              "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
              "          return comm_promise.then((comm) => {\n",
              "            comm.send(data, metadata, buffers, disposeOnDone);\n",
              "          });\n",
              "        };\n",
              "        var comm = {\n",
              "          send: sendClosure\n",
              "        };\n",
              "      }\n",
              "      window.PyViz.comms[comm_id] = comm;\n",
              "      return comm;\n",
              "    }\n",
              "    window.PyViz.comm_manager = new JupyterCommManager();\n",
              "    \n",
              "\n",
              "\n",
              "var JS_MIME_TYPE = 'application/javascript';\n",
              "var HTML_MIME_TYPE = 'text/html';\n",
              "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
              "var CLASS_NAME = 'output';\n",
              "\n",
              "/**\n",
              " * Render data to the DOM node\n",
              " */\n",
              "function render(props, node) {\n",
              "  var div = document.createElement(\"div\");\n",
              "  var script = document.createElement(\"script\");\n",
              "  node.appendChild(div);\n",
              "  node.appendChild(script);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when a new output is added\n",
              " */\n",
              "function handle_add_output(event, handle) {\n",
              "  var output_area = handle.output_area;\n",
              "  var output = handle.output;\n",
              "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "    return\n",
              "  }\n",
              "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "  if (id !== undefined) {\n",
              "    var nchildren = toinsert.length;\n",
              "    var html_node = toinsert[nchildren-1].children[0];\n",
              "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var scripts = [];\n",
              "    var nodelist = html_node.querySelectorAll(\"script\");\n",
              "    for (var i in nodelist) {\n",
              "      if (nodelist.hasOwnProperty(i)) {\n",
              "        scripts.push(nodelist[i])\n",
              "      }\n",
              "    }\n",
              "\n",
              "    scripts.forEach( function (oldScript) {\n",
              "      var newScript = document.createElement(\"script\");\n",
              "      var attrs = [];\n",
              "      var nodemap = oldScript.attributes;\n",
              "      for (var j in nodemap) {\n",
              "        if (nodemap.hasOwnProperty(j)) {\n",
              "          attrs.push(nodemap[j])\n",
              "        }\n",
              "      }\n",
              "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
              "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
              "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
              "    });\n",
              "    if (JS_MIME_TYPE in output.data) {\n",
              "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
              "    }\n",
              "    output_area._hv_plot_id = id;\n",
              "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
              "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
              "    } else {\n",
              "      window.PyViz.plot_index[id] = null;\n",
              "    }\n",
              "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "    var bk_div = document.createElement(\"div\");\n",
              "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var script_attrs = bk_div.children[0].attributes;\n",
              "    for (var i = 0; i < script_attrs.length; i++) {\n",
              "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "    }\n",
              "    // store reference to server id on output_area\n",
              "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when an output is cleared or removed\n",
              " */\n",
              "function handle_clear_output(event, handle) {\n",
              "  var id = handle.cell.output_area._hv_plot_id;\n",
              "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
              "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
              "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
              "  if (server_id !== null) {\n",
              "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
              "    return;\n",
              "  } else if (comm !== null) {\n",
              "    comm.send({event_type: 'delete', 'id': id});\n",
              "  }\n",
              "  delete PyViz.plot_index[id];\n",
              "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
              "    var doc = window.Bokeh.index[id].model.document\n",
              "    doc.clear();\n",
              "    const i = window.Bokeh.documents.indexOf(doc);\n",
              "    if (i > -1) {\n",
              "      window.Bokeh.documents.splice(i, 1);\n",
              "    }\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle kernel restart event\n",
              " */\n",
              "function handle_kernel_cleanup(event, handle) {\n",
              "  delete PyViz.comms[\"hv-extension-comm\"];\n",
              "  window.PyViz.plot_index = {}\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle update_display_data messages\n",
              " */\n",
              "function handle_update_output(event, handle) {\n",
              "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
              "  handle_add_output(event, handle)\n",
              "}\n",
              "\n",
              "function register_renderer(events, OutputArea) {\n",
              "  function append_mime(data, metadata, element) {\n",
              "    // create a DOM node to render to\n",
              "    var toinsert = this.create_output_subarea(\n",
              "    metadata,\n",
              "    CLASS_NAME,\n",
              "    EXEC_MIME_TYPE\n",
              "    );\n",
              "    this.keyboard_manager.register_events(toinsert);\n",
              "    // Render to node\n",
              "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "    render(props, toinsert[0]);\n",
              "    element.append(toinsert);\n",
              "    return toinsert\n",
              "  }\n",
              "\n",
              "  events.on('output_added.OutputArea', handle_add_output);\n",
              "  events.on('output_updated.OutputArea', handle_update_output);\n",
              "  events.on('clear_output.CodeCell', handle_clear_output);\n",
              "  events.on('delete.Cell', handle_clear_output);\n",
              "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
              "\n",
              "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "    safe: true,\n",
              "    index: 0\n",
              "  });\n",
              "}\n",
              "\n",
              "if (window.Jupyter !== undefined) {\n",
              "  try {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  } catch(err) {\n",
              "  }\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './seq_len=4/trial7/losses.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-da5beff641e4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhvplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./seq_len=4/trial7/losses.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m loss_fig = losses.hvplot(\n\u001b[1;32m      9\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss progress\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './seq_len=4/trial7/losses.csv'"
          ]
        }
      ],
      "source": [
        "import holoviews as hv\n",
        "import hvplot.pandas\n",
        "import pandas as pd\n",
        "\n",
        "hvplot.extension('matplotlib')\n",
        "\n",
        "losses = pd.read_csv(f\"./seq_len={seq_len}/losses.csv\")[\"0\"]\n",
        "loss_fig = losses.hvplot(\n",
        "    title=\"Training loss progress\", ylabel=\"loss\", xlabel=\"Training epochs\", logy=True\n",
        ").opts(fig_size=600, fontscale=2, aspect=1.2)\n",
        "loss_fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzyHW3KRdvMZ"
      },
      "source": [
        "Figure 3: The subsequence loss for each training\n",
        "iteration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy_6DE6KdvMZ"
      },
      "source": [
        "We see in Figure 3 that the loss continues to decrease until around the\n",
        "4,000th iteration. There, the model was erroraneous but is quick to\n",
        "recover as training continues. This may signal that the GPT model\n",
        "started focusing on learning something erroraneous too quickly. So, more\n",
        "regularization noise (like `dropout`) may be needed to help avoid this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNt0IUmSdvMZ"
      },
      "source": [
        "## Evaluation progress\n",
        "\n",
        "\n",
        "We now track the performance of the GPT model throughout its training in\n",
        "Figure 4 below. As mentioned before, after every 500th iteration, we let\n",
        "the model generate a batch of sequences. Alongside, we also return the\n",
        "total logits (predicted energies) used in the sequence generation. In\n",
        "Figure 4, the average predicted energies correspond to the red markers\n",
        "and the distribution of predicted energies is represented by the red\n",
        "area. Once we have the generated sequences, we can also let PennyLane\n",
        "calculate the true sequence energies. Similarly then, the blue markers\n",
        "are the average true energies and the blue area represents the true\n",
        "energy distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZCujnidvMZ"
      },
      "outputs": [],
      "source": [
        "df_true = pd.read_csv(f\"./seq_len={seq_len}/true_Es_t.csv\").iloc[:, 1:]\n",
        "df_pred = pd.read_csv(f\"./seq_len={seq_len}/pred_Es_t.csv\").iloc[:, 1:]\n",
        "\n",
        "df_true.columns = df_true.columns.astype(int)\n",
        "df_pred.columns = df_pred.columns.astype(int)\n",
        "\n",
        "df_trues_stats = pd.concat([df_true.mean(axis=0), df_true.min(axis=0), df_true.max(axis=0)], axis=1).reset_index()\n",
        "df_trues_stats.columns = [\"Training Iterations\", \"Ave True E\", \"Min True E\", \"Max True E\"]\n",
        "\n",
        "df_preds_stats = pd.concat([df_pred.mean(axis=0), df_pred.min(axis=0), df_pred.max(axis=0)], axis=1).reset_index()\n",
        "df_preds_stats.columns = [\"Training Iterations\", \"Ave Pred E\", \"Min Pred E\", \"Max Pred E\"]\n",
        "\n",
        "fig = (\n",
        "    df_trues_stats.hvplot.scatter(x=\"Training Iterations\", y=\"Ave True E\", label=\"Mean True Energies\") *\n",
        "    df_trues_stats.hvplot.line(x=\"Training Iterations\", y=\"Ave True E\", alpha=0.5, linewidth=1) *\n",
        "    df_trues_stats.hvplot.area(x=\"Training Iterations\", y=\"Min True E\", y2=\"Max True E\", alpha=0.1)\n",
        ") * (\n",
        "    df_preds_stats.hvplot.scatter(x=\"Training Iterations\", y=\"Ave Pred E\", label=\"Mean Predicted Energies\") *\n",
        "    df_preds_stats.hvplot.line(x=\"Training Iterations\", y=\"Ave Pred E\", alpha=0.5, linewidth=1) *\n",
        "    df_preds_stats.hvplot.area(x=\"Training Iterations\", y=\"Min Pred E\", y2=\"Max Pred E\", alpha=0.1)\n",
        ")\n",
        "fig = fig * hv.Curve([[0, grd_E], [10000, grd_E]], label=\"Ground State Energy\").opts(color=\"k\", alpha=0.4, linestyle=\"dashed\")\n",
        "fig = fig.opts(ylabel=\"Sequence Energies\", title=\"GQE Evaluations\", fig_size=600, fontscale=2)\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJP_uWqsdvMZ"
      },
      "source": [
        "Figure 4: True and predicted energies for sequences generated by the\n",
        "GPT model for each 500th training\n",
        "iteration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVUpfHiDdvMZ"
      },
      "source": [
        "We now see that the energies predicted by the model improve in accuracy,\n",
        "aligning more closely with the true energies during training. The\n",
        "increase in accuracy then allows the model to correctly sample states\n",
        "with lower energies. This is supported in Figure 4 where the sampled\n",
        "true energies get closer to the ground state energy (the dashed line).\n",
        "\n",
        "Note that at around the 4,000th iteration, the predicted energies are\n",
        "very far from the true energies. This makes sense considering our\n",
        "observation in Figure 3. Also note that at the 7,000th iteration, the\n",
        "averages of the predicted and true energies are the closest and even\n",
        "their respective spreads seem to have good overlap. This is when the\n",
        "best performing model version was saved, as seen in the training logs.\n",
        "For later iterations however, the predicted energies no longer improved.\n",
        "This may indicate that the GPT model has started overfitting on the\n",
        "training dataset in the later iterations. That is, the model became\n",
        "great at predicting the correct energies for the training set (as\n",
        "observed by the decreasing loss in Figure 3) but not great at\n",
        "generalizing on those outside the training set (like the sequences that\n",
        "the model generated on its own). One solution to avoid overfitting could\n",
        "then be online training. This is so that the GPT model is not restricted\n",
        "on a fixed dataset on which to overfit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh7QdnZ2dvMZ"
      },
      "source": [
        "## Sequence generation comparison\n",
        "\n",
        "\n",
        "Here, we compare some statistics of the true energies corresponding to\n",
        "sequences generated by a \\\"random\\\" model, the latest version of the\n",
        "model after all the training iterations, and the best model version\n",
        "saved based on the mean absolute error between the true and predicted\n",
        "energies during training (for our case, this is the model saved at the\n",
        "7,000th iteration). Note that we consider the training set to be\n",
        "generated by a random model since the token sequences are just sampled\n",
        "uniformly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVrPg7EjdvMZ"
      },
      "outputs": [],
      "source": [
        "# Latest model\n",
        "gen_token_seq_, _ = gpt.generate(\n",
        "    n_sequences=1024,\n",
        "    max_new_tokens=seq_len,\n",
        "    temperature=0.001,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "gen_inds_ = (gen_token_seq_[:, 1:] - 1).cpu().numpy()\n",
        "gen_op_seq_ = op_pool[gen_inds_]\n",
        "true_Es_ = get_subsequence_energies(gen_op_seq_)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Best model\n",
        "loaded = torch.load(f\"./seq_len={seq_len}/gqe.pt\")\n",
        "loaded_token_seq_, _ = loaded.generate(\n",
        "    n_sequences=1024,\n",
        "    max_new_tokens=seq_len,\n",
        "    temperature=0.001,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "loaded_inds_ = (loaded_token_seq_[:, 1:] - 1).cpu().numpy()\n",
        "loaded_op_seq_ = op_pool[loaded_inds_]\n",
        "loaded_true_Es_ = get_subsequence_energies(loaded_op_seq_)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Summary table\n",
        "df_compare_Es = pd.DataFrame({\n",
        "    \"Source\": [\"Random\", \"Latest Model\", \"Best Model\"],\n",
        "    \"Aves\": [train_sub_seq_en[:, -1].mean(), true_Es_.mean(), loaded_true_Es_.mean()],\n",
        "    \"Mins\": [train_sub_seq_en[:, -1].min(), true_Es_.min(), loaded_true_Es_.min()],\n",
        "    \"Maxs\": [train_sub_seq_en[:, -1].max(), true_Es_.max(), loaded_true_Es_.max()],\n",
        "    \"Mins_error\": [\n",
        "        abs(train_sub_seq_en[:, -1].min() - grd_E),\n",
        "        abs(true_Es_.min() - grd_E),\n",
        "        abs(loaded_true_Es_.min() - grd_E),\n",
        "    ],\n",
        "})\n",
        "df_compare_Es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YUzRBkCdvMa"
      },
      "source": [
        "We observe that the minimum energy corresponding to the random training\n",
        "set is already close to the ground state energy\n",
        "`grd_E=-1.1372633205048763 Ha` with an error of around `2.81e-04 Ha`.\n",
        "But we notice that the maximum energy is relatively far so the random\n",
        "sequences give a wider spread of energies.\n",
        "\n",
        "The energies of the generated sequences from the latest and the best GPT\n",
        "model versions however have a narrower spread and so, the average and\n",
        "the minimum energies are very close to `grd_E`, closer than those in the\n",
        "random training set. Namely, around a `2.25e-04 Ha` error for the\n",
        "minimum energy generated by the latest model version and a `7.71e-07 Ha`\n",
        "error for the best model version. It is then very interesting that a\n",
        "well-trained GPT model can generate sequences that are better than those\n",
        "in the training set, even though every sequence the model has seen just\n",
        "came from that set. That is, the model was able to generalize.\n",
        "\n",
        "Between the two GPT model versions, we see that the latest version is\n",
        "worse than the best version. The minimum energy error for the latest\n",
        "version has the same order of magnitude as the corresponding one for the\n",
        "random training set. Contrast this with the minimum energy error for the\n",
        "best version, which is 3 orders of magnitude smaller. This behavior is\n",
        "supported by our observation in Figure 4 where the performance of the\n",
        "model after the 7,000th iteration worsened. That is, the predicted\n",
        "energies started to deviate further from the true energies which in turn\n",
        "caused the states being sampled from these predicted energies to be\n",
        "different from the intended lower energy states.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOIBTafAdvMa"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "\n",
        "In this demo, we see that GPT-QE is a viable alternative in estimating\n",
        "the ground-state energy of a hydrogen molecule. The best underlying GPT\n",
        "model version can generate a state whose energy is only around\n",
        "`7.71e-07 Ha` away from ground state energy, which is well below the\n",
        "chemical accuracy. Additionally, since the GPT model being optimized is\n",
        "completely detached from the quantum simulations, gradients across a\n",
        "potentially large quantum circuit don\\'t need to be computed, for\n",
        "example. Thus, the machinery of classical ML can be harnessed without\n",
        "worrying too much about the quantum algorithm side of the problem.\n",
        "\n",
        "The reader can also experiment with other molecules from PennyLane and\n",
        "tweak several hyperparameters of the GPT model (like `dropout`, and\n",
        "`n_layer`) and include standard ML callbacks to its training (like an\n",
        "early stopping mechanism and a learning rate schedule). The code itself\n",
        "is also open to further optimization. For instance, using [PennyLane\n",
        "Lightning](https://docs.pennylane.ai/projects/lightning/en/stable/index.html)\n",
        "to evaluate the energies faster. An online training loop can also be\n",
        "implemented similarly to our offline version, the reader would just need\n",
        "to sample sequences from the current GPT model instead of a fixed\n",
        "dataset for each training iteration. To facilitate exploration and\n",
        "exploitation, one would also define a schedule for the inverse\n",
        "temperature. That is, initially letting the GPT model sample more\n",
        "randomly through a high temperature, then gradually decreasing so that\n",
        "the GPT model focuses more on the higher probability states (low\n",
        "energies).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQZTStAndvMa"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1. Kouhei Nakaji et al., The generative quantum eigensolver (GQE) and its application for ground state search. arXiv:2401.09253 (2024)\n",
        "2. Alec Radford et al., Language Models are Unsupervised Multitask Learners. OpenAI blog, 1(8):9 (2019)\n",
        "3. Ashish Vaswani et al., Attention is All you Need. Advances in Neural Information Processing Systems, 30 (2017)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}